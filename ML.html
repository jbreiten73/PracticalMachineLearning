<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Practical Machine Learning: Course Project</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>Practical Machine Learning: Course Project</h2>

<h2>Background</h2>

<p>Six young healthy male participants were asked to perform one set of 10 repitions of the Unilateral Dumpbell Biceps Curl in five different fashions: exactly according to the specification (Class A) , throwing the elbows to the front (Class  B), lifting the dumbbell only halfway (class C), lowering the dumbell only halfway (Class D) and throwing the hips to the front (class E). The goal of this project is to identify the execution type of the exercise by the information given from motion sensors on participants&#39; bodies.</p>

<h2>Getting data and preprocessing</h2>

<p>First I have to read in my data saved in my working directory, unifying the appearance of the &quot;NA&quot;-variables by converting empty strings as well as excel division error strings (#DIV/0!) in &quot;NA&quot;-variables:</p>

<pre><code class="r">training&lt;-read.csv(&quot;pml-training.csv&quot;, na.strings=c(&quot;&quot;,&quot;#DIV/0!&quot;,&quot;NA&quot;))
testing&lt;-read.csv(&quot;pml-testing.csv&quot;, na.strings=c(&quot;&quot;,&quot;#DIV/0!&quot;,&quot;NA&quot;))
dim(training)
</code></pre>

<pre><code>## [1] 19622   160
</code></pre>

<pre><code class="r">dim(testing)
</code></pre>

<pre><code>## [1]  20 160
</code></pre>

<p>Both datasets contain the same variables (with exception from the last, which is &quot;classe&quot; in &quot;training&quot; and &quot;problem_id&quot; in &quot;testing&quot;):</p>

<p>Typing str(training) reveals that the first seven columns are irrelevant as
predictors, so we set:</p>

<pre><code class="r">training&lt;-training[,-c(1:7)]
</code></pre>

<p>Also there seem to be variables with lots of &quot;NA&quot;. I decide to not include those variables with more than 80% &quot;NA&quot;-entries as predictors:</p>

<pre><code class="r">c&lt;-matrix(153,1)
for(i in 1:153)
{c[i]=ifelse( sum(is.na(training[,c(i)]))&gt;0.8*19622,i,0)}
print(c)
</code></pre>

<pre><code>##   [1]   0   0   0   0   5   6   7   8   9  10  11  12  13  14  15  16  17
##  [18]  18  19  20  21  22  23  24  25  26  27  28  29   0   0   0   0   0
##  [35]   0   0   0   0   0   0   0   0  43  44  45  46  47  48  49  50  51
##  [52]  52   0   0   0   0   0   0   0   0   0  62  63  64  65  66  67  68
##  [69]  69  70  71  72  73  74  75  76   0   0   0  80  81  82  83  84  85
##  [86]  86  87  88  89  90  91  92  93  94   0  96  97  98  99 100 101 102
## [103] 103 104 105   0   0   0   0   0   0   0   0   0   0   0   0 118 119
## [120] 120 121 122 123 124 125 126 127 128 129 130 131 132   0 134 135 136
## [137] 137 138 139 140 141 142 143   0   0   0   0   0   0   0   0   0   0
</code></pre>

<p>This leads to</p>

<pre><code class="r">training&lt;-training[,-c(5:29,43:52,62:76,80:94,96:105,118:132,134:143)]
</code></pre>

<p>Maybe we could reduce further prediction variables:</p>

<pre><code class="r">library(caret)
nzv&lt;-subset(nearZeroVar(training, saveMetrics=TRUE),zeroVar==TRUE |nzv==TRUE)
nzv
</code></pre>

<pre><code>## [1] freqRatio     percentUnique zeroVar       nzv          
## &lt;0 rows&gt; (or 0-length row.names)
</code></pre>

<p>This is obviously not the case.So we get the following prediction variables:</p>

<pre><code class="r">names(training[,-c(53)])
</code></pre>

<pre><code>##  [1] &quot;roll_belt&quot;            &quot;pitch_belt&quot;           &quot;yaw_belt&quot;            
##  [4] &quot;total_accel_belt&quot;     &quot;gyros_belt_x&quot;         &quot;gyros_belt_y&quot;        
##  [7] &quot;gyros_belt_z&quot;         &quot;accel_belt_x&quot;         &quot;accel_belt_y&quot;        
## [10] &quot;accel_belt_z&quot;         &quot;magnet_belt_x&quot;        &quot;magnet_belt_y&quot;       
## [13] &quot;magnet_belt_z&quot;        &quot;roll_arm&quot;             &quot;pitch_arm&quot;           
## [16] &quot;yaw_arm&quot;              &quot;total_accel_arm&quot;      &quot;gyros_arm_x&quot;         
## [19] &quot;gyros_arm_y&quot;          &quot;gyros_arm_z&quot;          &quot;accel_arm_x&quot;         
## [22] &quot;accel_arm_y&quot;          &quot;accel_arm_z&quot;          &quot;magnet_arm_x&quot;        
## [25] &quot;magnet_arm_y&quot;         &quot;magnet_arm_z&quot;         &quot;roll_dumbbell&quot;       
## [28] &quot;pitch_dumbbell&quot;       &quot;yaw_dumbbell&quot;         &quot;total_accel_dumbbell&quot;
## [31] &quot;gyros_dumbbell_x&quot;     &quot;gyros_dumbbell_y&quot;     &quot;gyros_dumbbell_z&quot;    
## [34] &quot;accel_dumbbell_x&quot;     &quot;accel_dumbbell_y&quot;     &quot;accel_dumbbell_z&quot;    
## [37] &quot;magnet_dumbbell_x&quot;    &quot;magnet_dumbbell_y&quot;    &quot;magnet_dumbbell_z&quot;   
## [40] &quot;roll_forearm&quot;         &quot;pitch_forearm&quot;        &quot;yaw_forearm&quot;         
## [43] &quot;total_accel_forearm&quot;  &quot;gyros_forearm_x&quot;      &quot;gyros_forearm_y&quot;     
## [46] &quot;gyros_forearm_z&quot;      &quot;accel_forearm_x&quot;      &quot;accel_forearm_y&quot;     
## [49] &quot;accel_forearm_z&quot;      &quot;magnet_forearm_x&quot;     &quot;magnet_forearm_y&quot;    
## [52] &quot;magnet_forearm_z&quot;
</code></pre>

<p>We subdivide the training set into a train section and a test section:</p>

<pre><code class="r">library(caret)
set.seed(36546)
trainingIndex  &lt;- createDataPartition(training$classe, p=.60, list=FALSE)
training.train &lt;- training[ trainingIndex,]
training.test  &lt;- training[-trainingIndex,]
</code></pre>

<p>As I now have divided my already classified data in a train and a test part, I would like to apply some prediction models and compare them to each other. </p>

<h2>Prediction with k-Nearest Neighbour Classification</h2>

<pre><code class="r">library(kknn)
set.seed(36546)
ModelKKNN&lt;-kknn(classe~.,training.train,training.test)
</code></pre>

<p>X contains the predictions for the variable classe for training.test by the k-Nearest Neighbour Algorithm:</p>

<pre><code class="r">X&lt;-as.factor(ModelKKNN$CL[,1])
</code></pre>

<p>Y contains the variable &quot;classe&quot; from the training.test dataset:</p>

<pre><code class="r">Y&lt;-training.test$classe
</code></pre>

<p>This leads to the following Confusion Matrix:</p>

<pre><code class="r">cm.KKNN&lt;-confusionMatrix(X,Y)
cm.KKNN
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2224   15    4    3    2
##          B    5 1475   14    0    5
##          C    2   25 1332   15    1
##          D    1    2   18 1267    6
##          E    0    1    0    1 1428
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9847          
##                  95% CI : (0.9817, 0.9873)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2e-16         
##                                           
##                   Kappa : 0.9807          
##  Mcnemar&#39;s Test P-Value : 0.01922         
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9964   0.9717   0.9737   0.9852   0.9903
## Specificity            0.9957   0.9962   0.9934   0.9959   0.9997
## Pos Pred Value         0.9893   0.9840   0.9687   0.9791   0.9986
## Neg Pred Value         0.9986   0.9932   0.9944   0.9971   0.9978
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2835   0.1880   0.1698   0.1615   0.1820
## Detection Prevalence   0.2865   0.1911   0.1752   0.1649   0.1823
## Balanced Accuracy      0.9961   0.9839   0.9835   0.9906   0.9950
</code></pre>

<h2>Prediction with Decision Trees</h2>

<pre><code class="r">library(rpart)
library(rpart.plot)
set.seed(36546)
modelRPART&lt;-rpart(classe ~ ., data=training.train, method=&quot;class&quot;)
</code></pre>

<p>Applying our model to the test portion of our training set:</p>

<pre><code class="r">predRPART &lt;- predict(modelRPART, training.test, type = &quot;class&quot;)
</code></pre>

<p>Plotting the Decision Tree as a (flipped) dendrogram:</p>

<pre><code class="r">library(ggplot2)
library(ggdendro)
ddata &lt;- dendro_data(modelRPART)
g&lt;-ggplot() + 
    geom_segment(data = ddata$segments, 
                 aes(x = x, y = y, xend = xend, yend = yend)) + 
    geom_text(data = ddata$labels, 
              aes(x = x, y = y, label = label), size = 3, vjust = 0) +
    geom_text(data = ddata$leaf_labels, 
              aes(x = x, y = y, label = label), size = 4, vjust = 1) +
    theme_dendro() + coord_flip()
print(g)
</code></pre>

<p><img src="figure/unnamed-chunk-14-1.png" alt="plot of chunk unnamed-chunk-14">
This leads to the following Confusion Matrix:</p>

<pre><code class="r">cm.RPART &lt;- confusionMatrix(predRPART, training.test$classe)
cm.RPART
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2003  331   23  116   47
##          B   64  850  215   70  167
##          C   61  178  953  122  100
##          D   93  119  125  907  199
##          E   11   40   52   71  929
## 
## Overall Statistics
##                                         
##                Accuracy : 0.7191        
##                  95% CI : (0.709, 0.729)
##     No Information Rate : 0.2845        
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16     
##                                         
##                   Kappa : 0.6433        
##  Mcnemar&#39;s Test P-Value : &lt; 2.2e-16     
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.8974   0.5599   0.6966   0.7053   0.6442
## Specificity            0.9079   0.9185   0.9288   0.9183   0.9728
## Pos Pred Value         0.7948   0.6223   0.6740   0.6286   0.8422
## Neg Pred Value         0.9570   0.8969   0.9355   0.9408   0.9239
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2553   0.1083   0.1215   0.1156   0.1184
## Detection Prevalence   0.3212   0.1741   0.1802   0.1839   0.1406
## Balanced Accuracy      0.9027   0.7392   0.8127   0.8118   0.8085
</code></pre>

<h2>Prediction with Random Forest</h2>

<pre><code class="r">library(randomForest)
set.seed(36546)
modelRF&lt;-randomForest(classe ~ ., data=training.train)
</code></pre>

<pre><code>## Error: cannot allocate vector of size 89.8 Mb
</code></pre>

<pre><code class="r">predRF &lt;- predict(modelRF, training.test, type = &quot;class&quot;)
plot(modelRF)
</code></pre>

<p><img src="figure/unnamed-chunk-16-1.png" alt="plot of chunk unnamed-chunk-16">
This leads to the following Confusion Matrix:</p>

<pre><code class="r">cm.RF &lt;- confusionMatrix(predRF, training.test$classe)
cm.RF
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2231   10    0    0    0
##          B    1 1501   10    0    0
##          C    0    7 1357   14    0
##          D    0    0    1 1272    5
##          E    0    0    0    0 1437
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9939          
##                  95% CI : (0.9919, 0.9955)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9923          
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9996   0.9888   0.9920   0.9891   0.9965
## Specificity            0.9982   0.9983   0.9968   0.9991   1.0000
## Pos Pred Value         0.9955   0.9927   0.9848   0.9953   1.0000
## Neg Pred Value         0.9998   0.9973   0.9983   0.9979   0.9992
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2843   0.1913   0.1730   0.1621   0.1832
## Detection Prevalence   0.2856   0.1927   0.1756   0.1629   0.1832
## Balanced Accuracy      0.9989   0.9935   0.9944   0.9941   0.9983
</code></pre>

<h2>Comparing of the Different Methods</h2>

<p>Compared with the other methods, the prediction with Decision trees results in a big out-of-sample-error (1-accuracy). The accuracy for Random Forest Prediction is very high (0.9939), even higher than the one for k-Nearest Neighbour Classification (0.9847), so we use it for our testing set:</p>

<pre><code class="r">pred&lt;- predict(modelRF,testing,type=&quot;class&quot;)
pred
</code></pre>

<pre><code>##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E
</code></pre>

</body>

</html>
